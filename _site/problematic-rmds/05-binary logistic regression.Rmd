---
  title: "Binary Logistic Regression"
  author: "Gepoliano Chaves"
  date: "June 24th, 2024"
  output:
    html_document:
      df_print: paged
      toc: true
  bibliography: references.bib
---

```{r}
library(expss)
```


Tutorial from https://www.r-bloggers.com/2020/05/binary-logistic-regression-with-r/

```{r}
library(readr)
adult <- read_csv("../data/adult.csv")
# Checking the structure of adult data
dim(adult)
```

```{r}
# Subsetting the data and keeping the required variables
adult <- adult[ ,c("workclass", "marital.status", "age", "income")]
names(adult)[names(adult) == 'income'] <- 'Class'
# Checking the dim
dim(adult)
```

### Summarizing categorical variable

```{r}
table(adult$workclass)
```

```{r}
# Combining levels
adult$workclass[adult$workclass == "Without-pay" | adult$workclass == "Never-worked"] <- "Unemployed"
adult$workclass[adult$workclass == "State-gov" | adult$workclass == "Local-gov"] <- "SL-gov"
adult$workclass[adult$workclass == "Self-emp-inc" | adult$workclass == "Self-emp-not-inc"] <- "Self-employed"

# Checking the table again
table(adult$workclass)
```

```{r}
# Generating the frequency table
table(adult$marital.status)
```

```{r}
# Combining levels
adult$marital.status[adult$marital.status == "Married-AF-spouse" | adult$marital.status == "Married-civ-spouse" | adult$marital.status == "Married-spouse-absent"] <- "Married"

adult$marital.status[adult$marital.status == "Divorced" |
                       adult$marital.status == "Separated" |
                       adult$marital.status == "Widowed"] <- "Not-Married"

# Checking the table again
table(adult$marital.status)
```

```{r}
# Converting to factor variables
adult$workclass <- as.factor(adult$workclass)
adult$marital.status <- as.factor(adult$marital.status)
adult$Class <- as.factor(adult$Class)
```


### Deleting the missing values

```{r}
# Converting ? to NA
adult[adult == "?"] <- NA

# Keeping only the na.omit() function
adult <- na.omit(adult)
```

### Finally taking a look into the target variable

```{r}
library(ggplot2)
ggplot(adult, aes(age)) +
  geom_histogram(aes(fill = Class), color = "black", binwidth = 2)
```

\

### Building the Model

\

```{r}
# Loading caret library
require(caret)
# Splitting the data into train and test
index <- createDataPartition(adult$Class, p = .70, list = FALSE)
train <- adult[index, ]
train

cross_cases(train, Class)

test <- adult[-index, ]
test

# Training the model
logistic_model <- glm(Class ~ ., family = binomial(), train)

# Checking the model
summary(logistic_model)
```


### Interpreting Logistic Regression Output

```{r, eval=F}
Sigmoid function, p = exp(-0.591532)/(1+exp(-0.591532))
```

### Predicting Dependent Variable(Y) in Test Dataset

```{r}
# Predicting in the test dataset
pred_prob <- predict(logistic_model, test, type = "response")
pred_prob
```

### Evaluating Logistic Regression Model

### Converting probability to class values in the training dataset

```{r}
# Converting from probability to actual output
train$pred_class <- ifelse(logistic_model$fitted.values >= 0.5, ">50K", "<=50K")

# Generating the classification table
ctab_train <- table(train$Class, train$pred_class)
ctab_train
```

### Training dataset converting from probability to class values

```{r}
# Converting from probability to actual output
test$pred_class <- ifelse(pred_prob >= 0.5, ">50K", "<=50K")

# Generating the classification table
ctab_test <- table(test$Class, test$pred_class)
ctab_test
```


### Accuracy

```{r}
## Accuracy = (TP + TN)/(TN + FP + FN + TP)


# Accuracy in Training dataset
accuracy_train <- sum(diag(ctab_train))/sum(ctab_train)*100
accuracy_train
```

```{r}
# Accuracy in Test dataset
accuracy_test <- sum(diag(ctab_test))/sum(ctab_test)*100
accuracy_test
```


A model is considered fairly good if the model accuracy is greater than 70%.

### Misclassification Rate

Misclassification Rate = (FP+FN)/(TN + FP + FN + TP)

### True Positive Rate â€“ Recall or Sensitivity

```{r}
# Recall Or TPR = TP/(FN + TP)


# Recall in Train dataset
Recall <- (ctab_train[2, 2]/sum(ctab_train[2, ]))*100
Recall
```

### True Negative Rate

```{r}
# TNR = TN/(TN + FP)


# TNR in Train dataset
TNR <- (ctab_train[1, 1]/sum(ctab_train[1, ]))*100
TNR
```

### Precision

```{r}
# Precision = TP/FP + TP


# Precision in Train dataset
Precision <- (ctab_train[2, 2]/sum(ctab_train[, 2]))*100
Precision
```

### Calculating F-Score

```{r}
F_Score <- (2 * Precision * Recall / (Precision + Recall))/100
F_Score
```

## ROC Curve

```{r}
library(pROC)
roc <- roc(train$Class, logistic_model$fitted.values)
roc
plot.roc(roc)
auc(roc)
```

### Concordance

```{r}
library(InformationValue)
Concordance(logistic_model$y,logistic_model$fitted.values)
```

### Confusion matrix

```{r, eval=F}
# Confusion Matrix
cf <- caret::confusionMatrix(table(pred_prob,test$Class))
cf
```
